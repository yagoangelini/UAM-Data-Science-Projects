{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, regexp_replace, trim, lower\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.conf import SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid search\n",
    "teste com outros algoritmos + parâmetros\n",
    "- como que várias árvores demora mais do que 1 só?\n",
    "cross validation\n",
    "seleção de atributos\n",
    "randomsplit diferente\n",
    "numero de pagina no rodapé\n",
    "mostrar linha do tempo/comparações de resultados\n",
    "todo o grupo precisa saber explicar\n",
    "\n",
    "atributos que tem uma correlação muito grande podem as vezes ser eliminados (duração do anime de acordo com tipo de mídia, ous eja, se aparece na tv geralmente tem 22 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) DEFINIÇÕES INICIAIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yagoc\\Documents\\Linguagem Java\\Programação para Ciência de Dados\\Projeto_TFIDF\n"
     ]
    }
   ],
   "source": [
    "# Capturar o dirname do caminho real para este arquivo .ipynb\n",
    "PATH = os.path.dirname(os.path.realpath('__file__'))\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir esquema do dataset\n",
    "esquema = 'id_documento STRING, assunto INT, titulo STRING, text STRING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'adj',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ago',\n",
       " 'ahead',\n",
       " \"ain't\",\n",
       " 'all',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'appear',\n",
       " 'appreciate',\n",
       " 'appropriate',\n",
       " 'are',\n",
       " \"aren't\",\n",
       " 'around',\n",
       " 'as',\n",
       " \"a's\",\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asking',\n",
       " 'associated',\n",
       " 'at',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awfully',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'backwards',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'begin',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'brief',\n",
       " 'but',\n",
       " 'by',\n",
       " 'came',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " \"can't\",\n",
       " 'caption',\n",
       " 'cause',\n",
       " 'causes',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'changes',\n",
       " 'clearly',\n",
       " \"c'mon\",\n",
       " 'co',\n",
       " 'co.',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'concerning',\n",
       " 'consequently',\n",
       " 'consider',\n",
       " 'considering',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'corresponding',\n",
       " 'could',\n",
       " \"couldn't\",\n",
       " 'course',\n",
       " \"c's\",\n",
       " 'currently',\n",
       " 'dare',\n",
       " \"daren't\",\n",
       " 'definitely',\n",
       " 'described',\n",
       " 'despite',\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'different',\n",
       " 'directly',\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'done',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'downwards',\n",
       " 'during',\n",
       " 'each',\n",
       " 'edu',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'eighty',\n",
       " 'either',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'end',\n",
       " 'ending',\n",
       " 'enough',\n",
       " 'entirely',\n",
       " 'especially',\n",
       " 'et',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'evermore',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'except',\n",
       " 'fairly',\n",
       " 'far',\n",
       " 'farther',\n",
       " 'few',\n",
       " 'fewer',\n",
       " 'fifth',\n",
       " 'first',\n",
       " 'five',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'for',\n",
       " 'forever',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forth',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'furthermore',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'greetings',\n",
       " 'had',\n",
       " \"hadn't\",\n",
       " 'half',\n",
       " 'happens',\n",
       " 'hardly',\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " \"here's\",\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'hi',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hither',\n",
       " 'hopefully',\n",
       " 'how',\n",
       " 'howbeit',\n",
       " 'however',\n",
       " 'hundred',\n",
       " \"i'd\",\n",
       " 'ie',\n",
       " 'if',\n",
       " 'ignored',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'immediate',\n",
       " 'in',\n",
       " 'inasmuch',\n",
       " 'inc',\n",
       " 'inc.',\n",
       " 'indeed',\n",
       " 'indicate',\n",
       " 'indicated',\n",
       " 'indicates',\n",
       " 'inner',\n",
       " 'inside',\n",
       " 'insofar',\n",
       " 'instead',\n",
       " 'into',\n",
       " 'inward',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " 'its',\n",
       " \"it's\",\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'k',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'know',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'last',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'lest',\n",
       " 'let',\n",
       " \"let's\",\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likely',\n",
       " 'likewise',\n",
       " 'little',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'ltd',\n",
       " 'made',\n",
       " 'mainly',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " \"mayn't\",\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meantime',\n",
       " 'meanwhile',\n",
       " 'merely',\n",
       " 'might',\n",
       " \"mightn't\",\n",
       " 'mine',\n",
       " 'minus',\n",
       " 'miss',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'mr',\n",
       " 'mrs',\n",
       " 'much',\n",
       " 'must',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'nd',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessary',\n",
       " 'need',\n",
       " \"needn't\",\n",
       " 'needs',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'neverf',\n",
       " 'neverless',\n",
       " 'nevertheless',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'ninety',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'none',\n",
       " 'nonetheless',\n",
       " 'noone',\n",
       " 'no-one',\n",
       " 'nor',\n",
       " 'normally',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'notwithstanding',\n",
       " 'novel',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'obviously',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " \"one's\",\n",
       " 'only',\n",
       " 'onto',\n",
       " 'opposite',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'ought',\n",
       " \"oughtn't\",\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'own',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'past',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'placed',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'possible',\n",
       " 'presumably',\n",
       " 'probably',\n",
       " 'provided',\n",
       " 'provides',\n",
       " 'que',\n",
       " 'quite',\n",
       " 'qv',\n",
       " 'rather',\n",
       " 'rd',\n",
       " 're',\n",
       " 'really',\n",
       " 'reasonably',\n",
       " 'recent',\n",
       " 'recently',\n",
       " 'regarding',\n",
       " 'regardless',\n",
       " 'regards',\n",
       " 'relatively',\n",
       " 'respectively',\n",
       " 'right',\n",
       " 'round',\n",
       " 'said',\n",
       " 'same',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'second',\n",
       " 'secondly',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'selves',\n",
       " 'sensible',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'seriously',\n",
       " 'seven',\n",
       " 'several',\n",
       " 'shall',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"shouldn't\",\n",
       " 'since',\n",
       " 'six',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'someday',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'specified',\n",
       " 'specify',\n",
       " 'specifying',\n",
       " 'still',\n",
       " 'sub',\n",
       " 'such',\n",
       " 'sup',\n",
       " 'sure',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'taking',\n",
       " 'tell',\n",
       " 'tends',\n",
       " 'th',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'thats',\n",
       " \"that's\",\n",
       " \"that've\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " \"there'd\",\n",
       " 'therefore',\n",
       " 'therein',\n",
       " \"there'll\",\n",
       " \"there're\",\n",
       " 'theres',\n",
       " \"there's\",\n",
       " 'thereupon',\n",
       " \"there've\",\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'third',\n",
       " 'thirty',\n",
       " 'this',\n",
       " 'thorough',\n",
       " 'thoroughly',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'till',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tried',\n",
       " 'tries',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " \"t's\",\n",
       " 'twice',\n",
       " 'two',\n",
       " 'un',\n",
       " 'under',\n",
       " 'underneath',\n",
       " 'undoing',\n",
       " 'unfortunately',\n",
       " 'unless',\n",
       " 'unlike',\n",
       " 'unlikely',\n",
       " 'until',\n",
       " 'unto',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'upwards',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'usually',\n",
       " 'v',\n",
       " 'value',\n",
       " 'various',\n",
       " 'versus',\n",
       " 'very',\n",
       " 'via',\n",
       " 'viz',\n",
       " 'vs',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'was',\n",
       " \"wasn't\",\n",
       " 'way',\n",
       " 'we',\n",
       " \"we'd\",\n",
       " 'welcome',\n",
       " 'well',\n",
       " \"we'll\",\n",
       " 'went',\n",
       " 'were',\n",
       " \"we're\",\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'whatever',\n",
       " \"what'll\",\n",
       " \"what's\",\n",
       " \"what've\",\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " \"where's\",\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'whichever',\n",
       " 'while',\n",
       " 'whilst',\n",
       " 'whither',\n",
       " 'who',\n",
       " \"who'd\",\n",
       " 'whoever',\n",
       " 'whole',\n",
       " \"who'll\",\n",
       " 'whom',\n",
       " 'whomever',\n",
       " \"who's\",\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'willing',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'wonder',\n",
       " \"won't\",\n",
       " 'would',\n",
       " \"wouldn't\",\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\",\n",
       " 'zero',\n",
       " 'a',\n",
       " \"how's\",\n",
       " 'i',\n",
       " \"when's\",\n",
       " \"why's\",\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'j',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'uucp',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " 'I',\n",
       " 'www',\n",
       " 'amount',\n",
       " 'bill',\n",
       " 'bottom',\n",
       " 'call',\n",
       " 'computer',\n",
       " 'con',\n",
       " 'couldnt',\n",
       " 'cry',\n",
       " 'de',\n",
       " 'describe',\n",
       " 'detail',\n",
       " 'due',\n",
       " 'eleven',\n",
       " 'empty',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'fill',\n",
       " 'find',\n",
       " 'fire',\n",
       " 'forty',\n",
       " 'front',\n",
       " 'full',\n",
       " 'give',\n",
       " 'hasnt',\n",
       " 'herse',\n",
       " 'himse',\n",
       " 'interest',\n",
       " 'itse”',\n",
       " 'mill',\n",
       " 'move',\n",
       " 'myse”',\n",
       " 'part',\n",
       " 'put',\n",
       " 'show',\n",
       " 'side',\n",
       " 'sincere',\n",
       " 'sixty',\n",
       " 'system',\n",
       " 'ten',\n",
       " 'thick',\n",
       " 'thin',\n",
       " 'top',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'abst',\n",
       " 'accordance',\n",
       " 'act',\n",
       " 'added',\n",
       " 'adopted',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affects',\n",
       " 'ah',\n",
       " 'announce',\n",
       " 'anymore',\n",
       " 'apparently',\n",
       " 'approximately',\n",
       " 'aren',\n",
       " 'arent',\n",
       " 'arise',\n",
       " 'auth',\n",
       " 'beginning',\n",
       " 'beginnings',\n",
       " 'begins',\n",
       " 'biol',\n",
       " 'briefly',\n",
       " 'ca',\n",
       " 'date',\n",
       " 'ed',\n",
       " 'effect',\n",
       " 'et-al',\n",
       " 'ff',\n",
       " 'fix',\n",
       " 'gave',\n",
       " 'giving',\n",
       " 'heres',\n",
       " 'hes',\n",
       " 'hid',\n",
       " 'home',\n",
       " 'id',\n",
       " 'im',\n",
       " 'immediately',\n",
       " 'importance',\n",
       " 'important',\n",
       " 'index',\n",
       " 'information',\n",
       " 'invention',\n",
       " 'itd',\n",
       " 'keys',\n",
       " 'kg',\n",
       " 'km',\n",
       " 'largely',\n",
       " 'lets',\n",
       " 'line',\n",
       " \"'ll\",\n",
       " 'means',\n",
       " 'mg',\n",
       " 'million',\n",
       " 'ml',\n",
       " 'mug',\n",
       " 'na',\n",
       " 'nay',\n",
       " 'necessarily',\n",
       " 'nos',\n",
       " 'noted',\n",
       " 'obtain',\n",
       " 'obtained',\n",
       " 'omitted',\n",
       " 'ord',\n",
       " 'owing',\n",
       " 'page',\n",
       " 'pages',\n",
       " 'poorly',\n",
       " 'possibly',\n",
       " 'potentially',\n",
       " 'pp',\n",
       " 'predominantly',\n",
       " 'present',\n",
       " 'previously',\n",
       " 'primarily',\n",
       " 'promptly',\n",
       " 'proud',\n",
       " 'quickly',\n",
       " 'ran',\n",
       " 'readily',\n",
       " 'ref',\n",
       " 'refs',\n",
       " 'related',\n",
       " 'research',\n",
       " 'resulted',\n",
       " 'resulting',\n",
       " 'results',\n",
       " 'run',\n",
       " 'sec',\n",
       " 'section',\n",
       " 'shed',\n",
       " 'shes',\n",
       " 'showed',\n",
       " 'shown',\n",
       " 'showns',\n",
       " 'shows',\n",
       " 'significant',\n",
       " 'significantly',\n",
       " 'similar',\n",
       " 'similarly',\n",
       " 'slightly',\n",
       " 'somethan',\n",
       " 'specifically',\n",
       " 'state',\n",
       " 'states',\n",
       " 'stop',\n",
       " 'strongly',\n",
       " 'substantially',\n",
       " 'successfully',\n",
       " 'sufficiently',\n",
       " 'suggest',\n",
       " 'thered',\n",
       " 'thereof',\n",
       " 'therere',\n",
       " 'thereto',\n",
       " 'theyd',\n",
       " 'theyre',\n",
       " 'thou',\n",
       " 'thoughh',\n",
       " 'thousand',\n",
       " 'throug',\n",
       " 'til',\n",
       " 'tip',\n",
       " 'ts',\n",
       " 'ups',\n",
       " 'usefully',\n",
       " 'usefulness',\n",
       " \"'ve\",\n",
       " 'vol',\n",
       " 'vols',\n",
       " 'wed',\n",
       " 'whats',\n",
       " 'wheres',\n",
       " 'whim',\n",
       " 'whod',\n",
       " 'whos',\n",
       " 'widely',\n",
       " 'words',\n",
       " 'world',\n",
       " 'youd',\n",
       " 'youre',\n",
       " 'http',\n",
       " 'amp',\n",
       " 'c',\n",
       " 'x']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir stopwords\n",
    "arquivo = open(os.path.join(PATH, 'stop_words_english.txt'), \"r\", encoding=\"utf8\")\n",
    "\n",
    "#Criar uma lista com as linhas do arquivo e ignorar quebras de linha ('\\n')\n",
    "list_stopwords = arquivo.read().splitlines()\n",
    "list_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **open(os.path.join(PATH, 'stop_words_english.txt'), \"r\", encoding=\"utf8\")** = Abrir arquivo das stopwords no modo read com codificação utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- UTF-8 (8-bit Unicode Transformation Format) é a codificação de caracteres mais comum da World Wide Web. Cada caractere é representado por um a quatro bytes. UTF-8 é compatível com versões anteriores do ASCII e pode representar qualquer caractere Unicode padrão.\n",
    "- Unicode é um padrão adotado mundialmente que possibilita com que todos os caracteres de todas as linguagens escritas utilizadas no planeta possam ser representados em computadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) SETUP SPARK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuração das propriedades do Spark\n",
    "config = SparkConf().setAll([('spark.executor.memory', '27g'), ('spark.executor.cores', '16'), ('spark.cores.max', '16'), ('spark.driver.memory','27g'),\n",
    "                             ('spark.sql.inMemoryColumnarStorage.compressed', True), ('spark.sql.inMemoryColumnarStorage.batchSize',10000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *https://spark.apache.org/docs/latest/configuration.html*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **SparkConf.setAll(pairs)** = Defina vários parâmetros, passados ​​como uma lista de pares no estilo (chave, valor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **spark.executor.memory** = Quantidade de memória a ser usada por processo do executor, no mesmo formato das strings de memória JVM com um sufixo de unidade de tamanho (\"k\", \"m\", \"g\" ou \"t\") (por exemplo 512m, 2g).\n",
    "- **spark.executor.cores** = O número de núcleos a serem usados ​​em cada executor.\n",
    "- **spark.cores.max** = A quantidade máxima de núcleos de CPU a serem solicitados para o aplicativo de todo o cluster (não de cada máquina).\n",
    "- **spark.driver.memory** = Quantidade de memória a ser usada para o processo do driver, ou seja, onde SparkContext é inicializado.\n",
    "- **spark.sql.inMemoryColumnarStorage.compressed** = Quando definido como True, o Spark SQL selecionará automaticamente um codec de compactação para cada coluna com base nas estatísticas dos dados.\n",
    "- **spark.sql.inMemoryColumnarStorage.batchSize** = Controla o tamanho dos lotes para armazenamento em cache colunar. Tamanhos de lote maiores podem melhorar a utilização e compactação da memória, mas arriscam OOMs ao armazenar dados em cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o Spark Context\n",
    "sc = SparkContext(master = 'local[2]', appName = 'Clasificação - Assunto News')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *https://spark.apache.org/docs/latest/api/java/org/apache/spark/SparkContext.html#SparkContext--*\n",
    "- *https://medium.com/data-hackers/entendo-funcionamento-do-pyspark-2b5ab4321ab9*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SparkContext representa a conexão a um cluster Spark.\n",
    "- O construtor alternativo **SparkContext(String master, String appName, SparkConf conf)** nos permite definir propriedades comuns do Spark diretamente.\n",
    "- O parâmetro master define a URL do cluster ao qual se conectar.\n",
    "- Só podemos ter um SparkContext ativo por Java Virtual Machine (JVM).\n",
    "\n",
    "- O Spark Context que é um processo Python que na verdade é apenas usado para comunicação local, este processo inicia uma JVM. Toda comunicação entre nós do clusters, entradas e saídas de arquivos são processadas na JVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LenovoYAC:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Clasificação - Assunto News</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=Clasificação - Assunto News>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch User Interface (UI)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a Spark Session\n",
    "spark = SparkSession(sc).builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) ABRINDO E VISUALIZANDO DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo dataset\n",
    "dataset = spark.read.csv(os.path.join(PATH, 'news.csv'), schema = esquema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **os.path.join(PATH, 'news.csv')** = Concatena a variável PATH e o nome do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id_documento': 0, 'assunto': 0, 'titulo': 0, 'text': 0}\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores nulos na coluna\n",
    "valores_missing = {col: dataset.filter(dataset[col].isNull()).count() for col in dataset.columns}\n",
    "print(valores_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **{col: dataset.filter(dataset[col].isNull()).count() for col in dataset.columns}** = Para cada coluna na lista de colunas do dataset, salve em um dicionário no formato (coluna : contagens de valores nulos da coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|assunto|count|\n",
      "+-------+-----+\n",
      "|      1| 1900|\n",
      "|      2| 1900|\n",
      "|      3| 1900|\n",
      "|      4| 1900|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exibir quantidade de notícias por assunto\n",
    "dataset.groupby('assunto').count().orderBy('assunto').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|id_documento|count|\n",
      "+------------+-----+\n",
      "|      000118|    1|\n",
      "|      000543|    1|\n",
      "|      001247|    1|\n",
      "|      001281|    1|\n",
      "|      001375|    1|\n",
      "|      001416|    1|\n",
      "|      001438|    1|\n",
      "|      002275|    1|\n",
      "|      002276|    1|\n",
      "|      002616|    1|\n",
      "|      002668|    1|\n",
      "|      003141|    1|\n",
      "|      003363|    1|\n",
      "|      003518|    1|\n",
      "|      003623|    1|\n",
      "|      004184|    1|\n",
      "|      004525|    1|\n",
      "|      004586|    1|\n",
      "|      004683|    1|\n",
      "|      005061|    1|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exibir quantidade de cada id (verificar se existem id's duplicados)\n",
    "dataset.groupby('id_documento').count().orderBy('count', ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4) TRANSFORMANDO DADOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renomear coluna 'assunto' para 'label'\n",
    "dataset = dataset.withColumnRenamed('assunto', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronização do Texto\n",
    "dataset = (dataset.withColumn(\"text\", regexp_replace(col(\"text\"), \"\\W+\", \" \")) # \\W+ remove caracteres especiais, como: \",@.()-;\n",
    "                  .withColumn(\"text\", regexp_replace(col(\"text\"), \"\\d+\", \" \"))  # remove dígitos\n",
    "                  .withColumn(\"text\", regexp_replace(col(\"text\"), \"^[a-z][^a-z]|[^a-z][a-z][^a-z]\", \" \"))  # substitua todas as letras sozinhas e iniciais sozinhas por espaço\n",
    "                  .withColumn(\"text\", regexp_replace(col(\"text\"), \"\\\\s+\", \" \"))  # remove espaços multiplicados\n",
    "                  .withColumn(\"text\", trim(col(\"text\")))  # remove espaços em branco no inicio e fim da string\n",
    "                  .withColumn(\"text\", lower(col(\"text\"))) # transforma todo o texto em minusculo\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2306"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divisão em treino e teste\n",
    "#70% para treino e 30% para teste\n",
    "(dados_treino, dados_teste) = dataset.randomSplit([0.7, 0.3], seed=157)\n",
    "\n",
    "dados_treino.count()\n",
    "dados_teste.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5) MODELAGEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "lr = LogisticRegression(maxIter = 100, regParam = 0.1)\n",
    "\n",
    "# Definição dos Stages\n",
    "tokenizer = Tokenizer(inputCol = 'text', outputCol = \"termos\")\n",
    "stopWordsRemover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"termos_sem_stopwords\").setStopWords(list_stopwords)\n",
    "hashingTF = HashingTF(inputCol = stopWordsRemover.getOutputCol(), outputCol = 'termos_HashTF')\n",
    "idf = IDF(inputCol = hashingTF.getOutputCol(), outputCol = 'features')\n",
    "\n",
    "# Criação do Pipeline\n",
    "pipeline = Pipeline(stages = [tokenizer, stopWordsRemover, hashingTF, idf, lr])\n",
    "\n",
    "model = pipeline.fit(dados_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O estágio **Tokenizer** envolve dividir uma frase em palavras menores. Ele converte o texto de entrada em umo conjunto de dados em tokens de palavras que nossa máquina possa entender.\n",
    "- O estágio **StopWordsRemover** extrai todas as palavras de parada disponíveis em nosso conjunto de dados. Palavras irrelevantes são um conjunto de palavras usadas com frequência em uma determinada frase. Essas palavras podem ser tendenciosas ao construir o classificador.\n",
    "- O estágio **TF-IDF** é uma medida estatística que indica a importância de uma palavra em relação a outros documentos em uma coleção de documentos. Isso cria uma relação entre diferentes palavras em um documento. Se uma palavra aparece com frequência em um determinado documento e também aparece com frequência em outros documentos, isso mostra que ela tem pouco poder preditivo para a classificação. Quanto mais a palavra é rara em determinados documentos, mais ela tem valor na análise preditiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(6) AVALIAÇÃO DO MODELO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849956634865568\n"
     ]
    }
   ],
   "source": [
    "avaliador = MulticlassClassificationEvaluator(predictionCol = 'prediction', labelCol = 'label', metricName = 'accuracy')\n",
    "\n",
    "prediction = model.transform(dados_teste)\n",
    "\n",
    "# Acurácia do Modelo\n",
    "print(avaliador.evaluate(prediction))\n",
    "\n",
    "# Confusion Matrix\n",
    "confusion_matrix = prediction.groupBy('label', 'prediction').count().orderBy('label', 'prediction')\n",
    "confusion_matrix.toPandas().to_csv(os.path.join(PATH, 'report_confusion_matrix.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(7) SALVAR E ENCERRAR PROCESSOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Salvando o Modelo\n",
    "# =============================================================================\n",
    "model.write().overwrite().save(os.path.join(PATH, 'model_best'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Stop User Interface\n",
    "# =============================================================================\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exibir quantidade de cada notícia (verificar se existem notícias duplicadas)\n",
    "#dataset.groupby('text', 'assunto').count().orderBy('count', ascending = False).show(truncate = True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a415b3f233e01a86496aa5fb17c63ce14c26e80e6ba039d477f661aea4409a5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
